
{
  "dataset_reader": {
      "type": "race",
      "transformer_model_name": "roberta-large"
  },
  "train_data_path": "train",
  "validation_data_path": "dev",
  "model": {
      "type": "transformer_mc",
      "transformer_model": "roberta-large"
  },
  "data_loader": {
    "sampler": "random",
    "batch_size": 4
  },
  "trainer": {
    "optimizer": {
      "type": "huggingface_adamw",
      "weight_decay": 0.01,
      "parameter_groups": [[["bias", "LayerNorm\\.weight", "layer_norm\\.weight"], {"weight_decay": 0}]],
      "lr": 1e-5,
      "eps": 1e-8,
      "correct_bias": true
    },
    "learning_rate_scheduler": {
      "type": "linear_with_warmup",
      "warmup_steps": 100
    },
    "num_epochs": 3,
    "num_gradient_accumulation_steps": 16,
    "patience": 3,
    "validation_metric": "+acc",
    "tensorboard_writer": {
        "summary_interval": 10,
        "should_log_learning_rate": true
    }
  },
  "random_seed": 42,
  "numpy_seed": 42,
  "pytorch_seed": 42
}
