{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/Casper/GIT/mice-snli/notebooks/evaluation.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/Casper/GIT/mice-snli/notebooks/evaluation.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/Casper/GIT/mice-snli/notebooks/evaluation.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(\u001b[39m\"\u001b[39m\u001b[39m..\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/Casper/GIT/mice-snli/notebooks/evaluation.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m html_highlight_diffs\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/Casper/GIT/mice-snli/notebooks/evaluation.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdisplay\u001b[39;00m \u001b[39mimport\u001b[39;00m display, HTML\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/Casper/GIT/mice-snli/notebooks/evaluation.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/GIT/mice-snli/notebooks/../src/utils.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m T5Tokenizer, T5Model, T5ForConditionalGeneration, \\\n\u001b[1;32m      2\u001b[0m         T5Config, T5TokenizerFast \n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mallennlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpredictors\u001b[39;00m \u001b[39mimport\u001b[39;00m Predictor, TextClassifierPredictor\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mallennlp_models\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclassification\u001b[39;00m \\\n\u001b[1;32m      5\u001b[0m         \u001b[39mimport\u001b[39;00m \u001b[39mStanfordSentimentTreeBankDatasetReader\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src.utils import html_highlight_diffs\n",
    "from IPython.core.display import display, HTML\n",
    "import numpy as np\n",
    "from src.edit_finder import EditEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import load_predictor, get_ints_to_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = \"snli\"\n",
    "STAGE2EXP = \"mice_binary\"\n",
    "EDIT_PATH = f\"../results/{TASK}/edits/{STAGE2EXP}/edits.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_edits(path):\n",
    "    edits = pd.read_csv(EDIT_PATH, sep=\"\\t\", lineterminator=\"\\n\", error_bad_lines=False, warn_bad_lines=True)\n",
    "\n",
    "    if edits['new_pred'].dtype == pd.np.dtype('float64'):\n",
    "        edits['new_pred'] = edits.apply(lambda row: str(int(row['new_pred']) if not np.isnan(row['new_pred']) else \"\"), axis=1)\n",
    "        edits['orig_pred'] = edits.apply(lambda row: str(int(row['orig_pred']) if not np.isnan(row['orig_pred']) else \"\"), axis=1)\n",
    "        edits['contrast_pred'] = edits.apply(lambda row: str(int(row['contrast_pred']) if not np.isnan(row['contrast_pred']) else \"\"), axis=1)\n",
    "    else:\n",
    "        edits['new_pred'].fillna(value=\"\", inplace=True)\n",
    "        edits['orig_pred'].fillna(value=\"\", inplace=True)\n",
    "        edits['contrast_pred'].fillna(value=\"\", inplace=True)\n",
    "    return edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_edits(edits):\n",
    "    \"\"\" MiCE writes all edits that are found in Stage 2, \n",
    "    but we only want to evaluate the smallest per input. \n",
    "    Calling get_sorted_e() \"\"\"\n",
    "    return edits[edits['sorted_idx'] == 0]\n",
    "    \n",
    "def evaluate_edits(edits):\n",
    "    temp = edits[edits['sorted_idx'] == 0]\n",
    "    minim = temp['minimality'].mean()\n",
    "    flipped = temp[temp['new_pred'].astype(str)==temp['contrast_pred'].astype(str)]\n",
    "    nunique = temp['data_idx'].nunique()\n",
    "    flip_rate = len(flipped)/nunique\n",
    "    duration=temp['duration'].mean()\n",
    "\n",
    "    fluency = 0.0\n",
    "    for _, row in edits.iterrows():\n",
    "      edit_evaluator = EditEvaluator()\n",
    "      orig_seg = row['orig_editable_seg']\n",
    "      orig_fluency = edit_evaluator.score_fluency(orig_seg)\n",
    "      edited_seg = row['edited_editable_seg']\n",
    "      edited_fluency = edit_evaluator.score_fluency(edited_seg)\n",
    "      fluency += edited_fluency / orig_fluency\n",
    "    fluency = fluency / len(edits)\n",
    "\n",
    "    metrics = {\n",
    "        \"num_total\": nunique,\n",
    "        \"num_flipped\": len(flipped),\n",
    "        \"flip_rate\": flip_rate,\n",
    "        \"minimality\": minim,\n",
    "        \"fluency\": fluency,\n",
    "        \"duration\": duration,\n",
    "    }\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k}: \\t{round(v, 3)}\")\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_edits(row):\n",
    "    html_original, html_edited = html_highlight_diffs(row['orig_editable_seg'], row['edited_editable_seg'])\n",
    "    minim = round(row['minimality'], 3)\n",
    "    print(f\"MINIMALITY: \\t{minim}\")\n",
    "    print(\"\")\n",
    "    display(HTML(html_original))\n",
    "    display(HTML(html_edited))\n",
    "\n",
    "def display_classif_results(rows):\n",
    "    for _, row in rows.iterrows():\n",
    "        orig_contrast_prob_pred = round(row['orig_contrast_prob_pred'], 3)\n",
    "        new_contrast_prob_pred = round(row['new_contrast_prob_pred'], 3)\n",
    "        print(\"-----------------------\")\n",
    "        print(f\"ORIG LABEL: \\t{row['orig_pred']}\")\n",
    "        print(f\"CONTR LABEL: \\t{row['contrast_pred']} (Orig Pred Prob: {orig_contrast_prob_pred})\")\n",
    "        print(f\"NEW LABEL: \\t{row['new_pred']} (New Pred Prob: {new_contrast_prob_pred})\")\n",
    "        print(\"\")\n",
    "        display_edits(row)\n",
    "\n",
    "def display_race_results(rows):\n",
    "    for _, row in rows.iterrows():\n",
    "        orig_contrast_prob_pred = round(row['orig_contrast_prob_pred'], 3)\n",
    "        new_contrast_prob_pred = round(row['new_contrast_prob_pred'], 3)\n",
    "        orig_input = eval(row['orig_input'])\n",
    "        options = orig_input['options']\n",
    "        print(\"-----------------------\")\n",
    "        print(f\"QUESTION: {orig_input['question']}\")\n",
    "        print(\"\\nOPTIONS:\")\n",
    "        for opt_idx, opt in enumerate(options):\n",
    "            print(f\"  ({opt_idx}) {opt}\")\n",
    "        print(f\"\\nORIG LABEL: \\t{row['orig_pred']}\")\n",
    "        print(f\"CONTR LABEL: \\t{row['contrast_pred']} (Orig Pred Prob: {orig_contrast_prob_pred})\")\n",
    "        print(f\"NEW LABEL: \\t{row['new_pred']} (New Pred Prob: {new_contrast_prob_pred})\")\n",
    "        print(\"\")\n",
    "        display_edits(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_total: \t235\n",
      "num_flipped: \t170\n",
      "flip_rate: \t0.723\n",
      "minimality: \t0.195\n",
      "duration: \t9.175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-dc0c135c78c7>:4: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  if edits['new_pred'].dtype == pd.np.dtype('float64'):\n"
     ]
    }
   ],
   "source": [
    "edits = read_edits(EDIT_PATH)\n",
    "edits = get_best_edits(edits)\n",
    "metrics = evaluate_edits(edits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "ORIG LABEL: \t1\n",
      "CONTR LABEL: \t0 (Orig Pred Prob: 0.001)\n",
      "NEW LABEL: \t0 (New Pred Prob: 0.831)\n",
      "\n",
      "MINIMALITY: \t0.106\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "All you could ever hope for if your a Jackass fan.As always <b>Knoxville</b> & his crew risk life & <b>limb</b> just for our viewing entertainment. If you are fan of the series & of the first movie you won't be let down like most <b>sequel</b> often do. The <b>jokes</b> they pull on each other as <b>twice</b> as funny,cruel,crude as ever before & the <b>stunts</b> & <b>dares</b> are twice as rough as any Jackass <b>episode</b> you have ever seen. If your a fan don't waste time go check it out for yourself because on Jackaass <b>standards</b> this movie is an <b>easy</b> <b>10</b> <b>out</b> of <b>10</b> just for the opening credits alone, I can't go into detail without <b>spoilers</b> but you've got to see it to believe it. "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "All you could ever hope for if your a  Jackass fan.As always  <b>Vaudeville</b> & his crew risk life &  <b>liberty</b> just for our viewing entertainment. If you are fan of the series & of the first movie you won't be  let down like most  <b>punks</b> often do. The  <b>characters</b> they pull on each other as  <b>thinly</b> as funny,cruel,crude as ever before & the  <b>editing</b> &  <b>editing</b> are twice as rough as any Jackass  <b>flick</b> you have ever seen. If your a fan don't waste time go check it out for yourself because on Jackaass  <b>ground</b> this movie is an  <b>absolute</b> <b>bore</b> of  <b>laughter</b> just for the opening credits alone, I can't go into detail without <b>spoiling</b> <b>it</b> but you've got to see it to believe it."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_rows = edits.sample(1)\n",
    "display_classif_results(random_rows)\n",
    "# display_race_results(random_rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
